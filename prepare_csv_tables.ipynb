{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_path = \"datasets/celeba/list_attr_celeba.txt\"\n",
    "partitions_path = 'datasets/celeba/list_eval_partition.txt'\n",
    "race_path = \"CelebA/races/races_ff.csv\"\n",
    "label_dir = \"CelebA/labels_split/\"\n",
    "img_celeb_dir = \"CelebA/cropped/\"\n",
    "img_created_dir = \"CelebA/augmented/raw_input_auto_gender_cropped\"\n",
    "races = [\"Black\", \"Indian\", \"Latino\", \"Middle Eastern\", \"Southeast Asian\", \"East Asian\", \"White\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all labels\n",
    "\n",
    "# all_labels = pd.read_csv(attributes_path, sep=\"\\s+\", skiprows=1).rename_axis(\"Image_Name\").reset_index().replace(-1, 0)\n",
    "# print(all_labels.head())\n",
    "\n",
    "# # create training and validation labels out off all_labels\n",
    "# y_train = all_labels[:size_train]\n",
    "# # y_train.columns = all_labels.columns\n",
    "# print(y_train.shape)\n",
    "\n",
    "# y_train = pd.DataFrame(columns=all_labels.columns)\n",
    "# for i, row in tqdm(all_labels[:size_train].iterrows(), total=size_train):\n",
    "#     img_number = f\"{(i+1):06}\"\n",
    "#     for j, race in enumerate(races):\n",
    "#         new_image_name = f\"{img_number}_{j}_{race.lower()}.jpg\"\n",
    "#         row[0] = new_image_name\n",
    "#         y_train = y_train.append(row)\n",
    "#     # if i == 0:\n",
    "#     #     break\n",
    "# print(y_train.shape)\n",
    "# y_train.to_csv(label_dir + \"created_train2.csv\")\n",
    "\n",
    "# y_val = all_labels[-1000:]\n",
    "# y_val.to_csv(label_dir + \"val.csv\")\n",
    "\n",
    "# y_test = all_labels[-2000:-1000]\n",
    "# y_test.to_csv(label_dir + \"test.csv\")\n",
    "\n",
    "# print(\"y_train shape:\", y_train.shape)\n",
    "# print(\"y_val shape:\", y_val.shape)\n",
    "# print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr = pd.read_csv(attributes_path, sep=\"\\s+\", skiprows=1)\n",
    "df_attr = df_attr.replace(-1, 0)\n",
    "df_attr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part = pd.read_csv(partitions_path, sep=\"\\s+\", skiprows=0, header=None)\n",
    "df_part.columns = ['Image_Name', 'Partition']\n",
    "df_part = df_part.set_index('Image_Name')\n",
    "print(df_part.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr_part = df_attr.merge(df_part, left_index=True, right_index=True)\n",
    "df_attr_part.index = df_attr_part.index.rename('Image_Name')\n",
    "print(df_attr_part.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_race = pd.read_csv(race_path, usecols=[\"face_name_align\", \"race\"])\n",
    "df_race.columns = ['Image_Name', 'Race']\n",
    "df_race = df_race.set_index('Image_Name')\n",
    "print(df_race.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df_attr_part.merge(df_race, left_index=True, right_index=True)\n",
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realize standard celeba split\n",
    "train_set = df_total.loc[df_total['Partition'] == 0].drop(\"Partition\", axis=1)\n",
    "val_set = df_total.loc[df_total['Partition'] == 1].drop(\"Partition\", axis=1)\n",
    "test_set = df_total.loc[df_total['Partition'] == 2].drop(\"Partition\", axis=1)\n",
    "\n",
    "print(len(train_set), len(val_set), len(test_set))\n",
    "# train_set.to_csv(label_dir + 'train_total.csv')\n",
    "# val_set.to_csv(label_dir + 'val_total.csv')\n",
    "# test_set.to_csv(label_dir + 'test_total.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training labels for augmented data (expecting leading sample)\n",
    "# size_augmented_data = 1000\n",
    "# df_attr_prepared = df_attr[:size_augmented_data].rename_axis(\"Image_Name\").reset_index()\n",
    "# train_set_aug = pd.DataFrame(columns=df_attr_prepared.columns)\n",
    "# # print(train_set_aug.head())\n",
    "# for i, row in tqdm(df_attr_prepared.iterrows(), total=size_augmented_data):\n",
    "#     img_number = f\"{(i+1):06}\"\n",
    "#     for j, race in enumerate(races):\n",
    "#         new_image_name = f\"{img_number}_{j}_{race.lower()}.jpg\"\n",
    "#         row[0] = new_image_name\n",
    "#         row[\"Race\"] = race\n",
    "#         train_set_aug = train_set_aug.append(row)\n",
    "# train_set_aug = train_set_aug.set_index(\"Image_Name\")\n",
    "# print(train_set_aug.shape)\n",
    "# train_set_aug.to_csv(label_dir + f\"train_aug_{size_augmented_data}_samples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split validation set by race\n",
    "# grouped_df = val_set.groupby(val_set.Race)\n",
    "# val_races = []\n",
    "# print(f\"Validation set ({len(val_set)} images):\")\n",
    "# for race in races:\n",
    "#       val_race = grouped_df.get_group(race)\n",
    "#       print(f\"{race}: {len(val_race)}\", end=\"\\t\")\n",
    "#       val_race.to_csv(label_dir+\"val/\"+race+\".csv\")\n",
    "# print(\"\\n\")\n",
    "\n",
    "# # split test set by race\n",
    "# grouped_df = test_set.groupby(test_set.Race)\n",
    "# test_races = []\n",
    "# print(f\"Test set ({len(val_set)} images):\")\n",
    "# for race in races:\n",
    "#       test_race = grouped_df.get_group(race)\n",
    "#       print(f\"{race}: {len(test_race)}\", end=\"\\t\")\n",
    "#       test_race.to_csv(label_dir+\"test/\"+race+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take random train sample\n",
    "# size_sample = 500\n",
    "# rand_perm = np.random.permutation(len(train_set))\n",
    "# sample_set = train_set.iloc[rand_perm[:size_sample]]\n",
    "# sample_set.to_csv(label_dir + f'train_{size_sample}_samples_shuffled.csv')\n",
    "# print(sample_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # take leading train sample\n",
    "# size_sample = 1000\n",
    "# only_white = train_set[train_set[\"Race\"] == \"White\"]\n",
    "# sample_set = only_white[:size_sample]\n",
    "# sample_set.to_csv(label_dir + f'train_{size_sample}_samples_only_white.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take random train sample\n",
    "# size_sample = 86744\n",
    "# only_white = train_set[train_set[\"Race\"] == \"White\"]\n",
    "# print(len(only_white))\n",
    "# sample_set = train_set.sample(n=size_sample)\n",
    "# sample_set.to_csv(label_dir + f'train_{size_sample}_samples_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ff_train_set = pd.read_csv(\"fairface/dataset/fairface_label_train.csv\")\n",
    "# ff_train_set = ff_train_set.sample(n=30000)\n",
    "# ff_train_set.to_csv(\"fairface/dataset/fairface_label_train_30000_samples.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
