{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate maximum crop from CelebA images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the quadratic bbox of maximal size (without padding) that is as centered as possible around the face\n",
    "def calculate_crop(image, face_bbox):\n",
    "\n",
    "    # find centre of bbox\n",
    "    c_x = face_bbox[0] + face_bbox[2] // 2\n",
    "    c_y = face_bbox[1] + face_bbox[3] // 2\n",
    "    # print(\"center:\", (c_x, c_y))\n",
    "\n",
    "\n",
    "    if image.width <= image.height:\n",
    "        crop_size = image.width\n",
    "        left = 0\n",
    "        right = crop_size\n",
    "        top = c_y - crop_size // 2\n",
    "        bottom = c_y + crop_size // 2\n",
    "\n",
    "        if top < 0:\n",
    "            bottom -= top\n",
    "            top = 0\n",
    "        if bottom > image.height:\n",
    "            overlap = bottom - image.height\n",
    "            top -= overlap\n",
    "            bottom = image.height\n",
    "\n",
    "    else:\n",
    "        crop_size = image.height\n",
    "        top = 0\n",
    "        bottom = crop_size\n",
    "        left = c_x - crop_size // 2\n",
    "        right = c_x + crop_size // 2\n",
    "\n",
    "        if left < 0:\n",
    "            right -= left\n",
    "            left = 0\n",
    "        if right > image.width:\n",
    "            overlap = right - image.width\n",
    "            left -= overlap\n",
    "            right = image.width\n",
    "\n",
    "    return np.array((left, top, right, bottom)), crop_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and save bounding boxes of cropped images from CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating crops: 100%|██████████| 10000/10000 [02:16<00:00, 73.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bounding boxes of cropped images here: 'CelebA/augmentations/bboxes_cropped/448_px_first_10k.csv_last'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# set parameters\n",
    "bb_path = \"./datasets/celeba/list_bbox_celeba.txt\"\n",
    "img_dir = \"CelebA/uncropped\"\n",
    "output_size = (448, 448)\n",
    "new_bboxes_path = f\"CelebA/augmentations/bboxes_cropped/{output_size[0]}_px_first_10k.csv\"\n",
    "\n",
    "min_index = 1 # 1\n",
    "max_index = 10000 #202599\n",
    "\n",
    "\n",
    "# format: (left, top, width, height)\n",
    "face_bboxes = []\n",
    "with open(bb_path, \"r\") as f:\n",
    "    face_bboxes = f.readlines()\n",
    "\n",
    "columns_result = [\"Image_Name\", \"Left\", \"Top\", \"Right\",  \"Bottom\"]\n",
    "new_bboxes = pd.DataFrame(columns=columns_result)\n",
    "\n",
    "# iterate through all images specified\n",
    "for img_nmb in tqdm(range(min_index, max_index + 1), desc=\"Creating crops\"):\n",
    "    img_number = f\"{img_nmb:06}\"\n",
    "\n",
    "    path = f\"{img_dir}/{img_number}.jpg\"\n",
    "\n",
    "    image = Image.open(path)\n",
    "    # image.show()\n",
    "    # print(\"original image size:\" , image.size)\n",
    "\n",
    "    # get bbox position\n",
    "\n",
    "    # print(face_bboxes[img_nmb + 1])\n",
    "    face_bbox = face_bboxes[img_nmb + 1].split()[1:]\n",
    "    if img_nmb == 101283:\n",
    "        face_bbox = [70, 570, 550, 400]\n",
    "\n",
    "    face_bbox = [int(value) for value in face_bbox]\n",
    "    # print(face_bbox)\n",
    "    \n",
    "\n",
    "    # crop the image: (left, top, right, bottom)\n",
    "    image_crop, crop_size = calculate_crop(image, face_bbox)\n",
    "    # print(\"crop:\", image_crop)\n",
    "\n",
    "    scaling_factor = output_size[0] / crop_size\n",
    "    face_left = face_bbox[0] - image_crop[0]\n",
    "    face_right = face_left + face_bbox[2]\n",
    "    face_top = face_bbox[1] - image_crop[1]\n",
    "    face_bottom = face_top + face_bbox[3]\n",
    "    new_face_bb = np.array((face_left, face_top, face_right, face_bottom)) * scaling_factor\n",
    "    new_face_bb = np.round(new_face_bb).astype(int)\n",
    "\n",
    "    image = image.crop(image_crop)\n",
    "    image = image.resize(output_size, Image.Resampling.LANCZOS)\n",
    "    # print(\"output image size\", image.size)\n",
    "    # image.show()\n",
    "\n",
    "    image = image.crop(new_face_bb)\n",
    "    new_row = {columns_result[0]: f\"{img_number}.jpg\", \n",
    "               columns_result[1]: new_face_bb[0],\n",
    "               columns_result[2]: new_face_bb[1],\n",
    "               columns_result[3]: new_face_bb[2],\n",
    "               columns_result[4]: new_face_bb[3]\n",
    "               }\n",
    "    new_bboxes = new_bboxes.append(new_row, ignore_index=True)\n",
    "\n",
    "    # image.show()\n",
    "\n",
    "    # image.save(f\"fairface/detected_faces_CelebA_10k_aug_samples//{img_number}.jpg\")\n",
    "\n",
    "# save new bounding boxes as csv\n",
    "# print(new_bboxes)\n",
    "new_bboxes.to_csv(new_bboxes_path, mode=\"a\")\n",
    "print(f\"Saved bounding boxes of cropped images here: '{new_bboxes_path}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
