{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Look up structure\n",
    "# 2. Load x_train, extract y_train\n",
    "# 3. Load x_val/x_test, create/extract y_val/y_test\n",
    "# 4. write down classifier\n",
    "# 5. train classifier\n",
    "# 6. evaluate classifier with test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.system(\"pip install pandas\")\n",
    "# os.system(\"pip install torchvision\")\n",
    "os.system(\"CUDA_LAUNCH_BLOCKING=1\")\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet101, resnet34, ResNet101_Weights, ResNet34_Weights\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths and constants\n",
    "attributes_path = \"datasets/celeba/list_attr_celeba.txt\"\n",
    "partitions_path = 'datasets/celeba/list_eval_partition.txt'\n",
    "race_path = \"CelebA/races/races_ff.csv\"\n",
    "label_dir = \"CelebA/labels_split/\"\n",
    "img_celeb_dir = \"CelebA/cropped/\"\n",
    "img_created_dir = \"CelebA/augmented/raw_input_auto_gender_cropped\"\n",
    "train_data_path = \"\"\n",
    "\n",
    "size_train = 500\n",
    "size_val = 1000\n",
    "use_baseline = False\n",
    "images_per_image_id = 1 if use_baseline else 7\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 9e-5 if use_baseline else 7e-5\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Architecture\n",
    "FEATURE_SIZE = (512, 512)\n",
    "BATCH_SIZE_TRAIN = 128\n",
    "BATCH_SIZE_VAL = 128\n",
    "BATCH_SIZE_TEST = 128\n",
    "DEVICE = 'cuda:0'\n",
    "\n",
    "\n",
    "races = [\"Black\", \"Indian\", \"Latino\", \"Middle Eastern\", \"Southeast Asian\", \"East Asian\", \"White\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all labels\n",
    "\n",
    "# all_labels = pd.read_csv(attributes_path, sep=\"\\s+\", skiprows=1).rename_axis(\"Image_Name\").reset_index().replace(-1, 0)\n",
    "# print(all_labels.head())\n",
    "\n",
    "# # create training and validation labels out off all_labels\n",
    "# y_train = all_labels[:size_train]\n",
    "# # y_train.columns = all_labels.columns\n",
    "# print(y_train.shape)\n",
    "\n",
    "# y_train = pd.DataFrame(columns=all_labels.columns)\n",
    "# for i, row in tqdm(all_labels[:size_train].iterrows(), total=size_train):\n",
    "#     img_number = f\"{(i+1):06}\"\n",
    "#     for j, race in enumerate(races):\n",
    "#         new_image_name = f\"{img_number}_{j}_{race.lower()}.jpg\"\n",
    "#         row[0] = new_image_name\n",
    "#         y_train = y_train.append(row)\n",
    "#     # if i == 0:\n",
    "#     #     break\n",
    "# print(y_train.shape)\n",
    "# y_train.to_csv(label_dir + \"created_train2.csv\")\n",
    "\n",
    "# y_val = all_labels[-1000:]\n",
    "# y_val.to_csv(label_dir + \"val.csv\")\n",
    "\n",
    "# y_test = all_labels[-2000:-1000]\n",
    "# y_test.to_csv(label_dir + \"test.csv\")\n",
    "\n",
    "# print(\"y_train shape:\", y_train.shape)\n",
    "# print(\"y_val shape:\", y_val.shape)\n",
    "# print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lab = pd.read_csv(attributes_path, sep=\"\\s+\", skiprows=1, usecols=['Male'])\n",
    "\n",
    "# # Make 0 (female) & 1 (male) labels instead of -1 & 1\n",
    "# df_lab.loc[df_lab['Male'] == -1, 'Male'] = 0\n",
    "\n",
    "# df_lab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_part = pd.read_csv(partitions_path, sep=\"\\s+\", skiprows=0, header=None)\n",
    "# df_part.columns = ['Image_Name', 'Partition']\n",
    "# df_part = df_part.set_index('Image_Name')\n",
    "# print(df_part.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lab_part = df_lab.merge(df_part, left_index=True, right_index=True)\n",
    "# df_lab_part.index = df_lab_part.index.rename('Image_Name')\n",
    "# # df6 = df_lab_part[:3]\n",
    "# # df6.columns = ['Male', 'Partition']\n",
    "\n",
    "# # print(df6)\n",
    "# print(df_lab_part.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_race = pd.read_csv(race_path)\n",
    "# df_race.columns = ['Image_Name', 'Race', 'Race_Scores']\n",
    "# df_race = df_race.set_index('Image_Name')\n",
    "# df_race = df_race['Race']\n",
    "# print(df_race.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_total = df_lab_part.merge(df_race, left_index=True, right_index=True) #how=\"left\",\n",
    "# df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = df_total.loc[df_total['Partition'] == 0][:size_train]\n",
    "# df_lab_prepared = df_lab[:size_train].rename_axis(\"Image_Name\").reset_index()\n",
    "# train_set = pd.DataFrame(columns=df_lab_prepared.columns)\n",
    "# # print(train_set)\n",
    "# for i, row in tqdm(df_lab_prepared.iterrows(), total=size_train):\n",
    "#     # print(i)\n",
    "#     # img_number = i.split(\".\")[0]\n",
    "#     img_number = f\"{(i+1):06}\"\n",
    "#     for j, race in enumerate(races):\n",
    "#         new_image_name = f\"{img_number}_{j}_{race.lower()}.jpg\"\n",
    "#         row[0] = new_image_name\n",
    "#         row[\"Race\"] = race\n",
    "#         train_set = train_set.append(row)\n",
    "# print(train_set.shape)\n",
    "# train_set.to_csv(label_dir + \"gender_train_500.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# val_set = df_total.loc[df_total['Partition'] == 1]\n",
    "# test_set = df_total.loc[df_total['Partition'] == 2]\n",
    "\n",
    "# print(len(train_set), len(val_set), len(test_set))\n",
    "# print(val_set.head())\n",
    "# train_set.to_csv('celeba-gender-train.csv')\n",
    "# val_set.to_csv('celeba-gender-val.csv')\n",
    "# test_set.to_csv('celeba-gender-test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split validation set by race\n",
    "# grouped_df = val_set.groupby(val_set.Race)\n",
    "# val_races = []\n",
    "# print(f\"Validation set ({len(val_set)} images):\")\n",
    "# for race in races:\n",
    "#       val_race = grouped_df.get_group(race)\n",
    "#       print(f\"{race}: {len(val_race)}\", end=\"\\t\")\n",
    "#       val_race.to_csv(label_dir+\"val/\"+race+\".csv\")\n",
    "# print(\"\\n\")\n",
    "\n",
    "# # split test set by race\n",
    "# grouped_df = test_set.groupby(test_set.Race)\n",
    "# test_races = []\n",
    "# print(f\"Test set ({len(val_set)} images):\")\n",
    "# for race in races:\n",
    "#       test_race = grouped_df.get_group(race)\n",
    "#       print(f\"{race}: {len(test_race)}\", end=\"\\t\")\n",
    "#       test_race.to_csv(label_dir+\"test/\"+race+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebaDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
    "\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "    \n",
    "        df = pd.read_csv(csv_path, index_col=None)\n",
    "        self.img_dir = img_dir\n",
    "        self.csv_path = csv_path\n",
    "        self.img_names = df[\"Image_Name\"].values\n",
    "        self.races = df[\"Race\"].values\n",
    "        self.y = df['Male'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.img_names[index]))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = self.y[index]\n",
    "        gt_race = self.races[index]\n",
    "        return img, label, gt_race\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_transform = transforms.Compose([transforms.Resize(FEATURE_SIZE),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "train_csv = \"gender_train_500.csv\" if use_baseline else \"created_train.csv\"\n",
    "train_img_dir = img_celeb_dir if use_baseline else img_created_dir\n",
    "\n",
    "train_dataset = CelebaDataset(csv_path=label_dir + train_csv,\n",
    "                              img_dir=train_img_dir,\n",
    "                              transform=custom_transform)\n",
    "\n",
    "val_dataset_total = CelebaDataset(csv_path=label_dir + \"gender_val.csv\",\n",
    "                              img_dir=img_celeb_dir,\n",
    "                              transform=custom_transform)\n",
    "\n",
    "test_dataset_total = CelebaDataset(csv_path=label_dir + \"gender_test.csv\",\n",
    "                              img_dir=img_celeb_dir,\n",
    "                              transform=custom_transform)\n",
    "\n",
    "num_workers = 8\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE_TRAIN,\n",
    "                          shuffle=True,\n",
    "                          num_workers=num_workers)\n",
    "\n",
    "val_loader_total = DataLoader(dataset=val_dataset_total,\n",
    "                          batch_size=BATCH_SIZE_VAL,\n",
    "                          shuffle=False,\n",
    "                          num_workers=num_workers)\n",
    "\n",
    "test_loader_total = DataLoader(dataset=test_dataset_total,\n",
    "                          batch_size=BATCH_SIZE_TEST,\n",
    "                          shuffle=False,\n",
    "                          num_workers=16)\n",
    "\n",
    "\n",
    "# split in 7 races\n",
    "\n",
    "# val_loaders = []\n",
    "# for race in races:\n",
    "#     ds = CelebaDataset(csv_path=f\"{label_dir}/val/{race}.csv\",\n",
    "#                         img_dir=img_celeb_dir,\n",
    "#                         transform=custom_transform)\n",
    "#     dl = DataLoader(dataset=ds,\n",
    "#                     batch_size=BATCH_SIZE_VAL,\n",
    "#                     shuffle=False,\n",
    "#                     num_workers=num_workers)\n",
    "#     val_loaders.append(dl)\n",
    "\n",
    "\n",
    "# test_loaders = []\n",
    "# for race in races:\n",
    "#     ds = CelebaDataset(csv_path=f\"{label_dir}/test/{race}.csv\",\n",
    "#                               img_dir=img_celeb_dir,\n",
    "#                               transform=custom_transform)\n",
    "#     dl = DataLoader(dataset=ds,\n",
    "#                     batch_size=BATCH_SIZE_TEST,\n",
    "#                     shuffle=False,\n",
    "#                     num_workers=num_workers)\n",
    "#     test_loaders.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part1 = pd.read_csv(\"race_total.csv\")\n",
    "# part2 = pd.read_csv(\"race_total_2.csv\")\n",
    "# part3 = pd.read_csv(\"race_total_3.csv\")\n",
    "# total = pd.concat([part1, part2, part3]).sort_values(\"face_name_align\")\n",
    "# total = total.set_index(\"face_name_align\")\n",
    "# print(total.head())\n",
    "# total.to_csv(\"race_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "##########################\n",
    "### COST AND OPTIMIZER\n",
    "##########################\n",
    "\n",
    "\n",
    "# model = resnet101(weights=ResNet101_Weights.DEFAULT)\n",
    "model = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "model.to(DEVICE)\n",
    "fc_layer = nn.Linear(1000, 1, device=DEVICE)\n",
    "sigmoid = nn.Sigmoid()\n",
    "tanh = nn.Tanh()\n",
    "# softmax = nn.Softmax()\n",
    "relu = nn.ReLU()\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "bin_ce = nn.BCELoss()\n",
    "# cost_fn = torch.nn.CrossEntropyLoss()  \n",
    "params = list(model.parameters()) + list(fc_layer.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elapsed_time(start_time):\n",
    "    elapsed = int(time.time() - start_time)\n",
    "    m, s = divmod(elapsed, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return f\"{h}:{m:02d}:{s:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader = val_loaders[6]\n",
    "\n",
    "# correct_predictions = np.zeros(len(races))\n",
    "# true_pos = np.zeros(len(races))\n",
    "# true_neg = np.zeros(len(races))\n",
    "# positive_preds = np.zeros(len(races))\n",
    "# positive_targets = np.zeros(len(races))\n",
    "# num_examples = np.zeros(len(races))\n",
    "# total_examples = len(data_loader.dataset) \n",
    "\n",
    "\n",
    "# print(\"Evaluating...\")\n",
    "# total_it = int(np.ceil(total_examples / data_loader.batch_size))\n",
    "# for i, (features, targets, gt_races) in tqdm(enumerate(data_loader), total=total_it):\n",
    "#     prediction = np.random.randint(2, size=targets.shape)\n",
    "#     targets = targets.numpy()\n",
    "#     gt_races = np.array([races.index(race) for race in gt_races])\n",
    "    \n",
    "#     for j in range(len(races)):\n",
    "#         correct_preds = (gt_races == j) & (prediction == targets)\n",
    "#         true_pos[j] += (correct_preds & (prediction == 1)).sum()\n",
    "#         true_neg[j] += (correct_preds & (prediction == 0)).sum()\n",
    "#         correct_predictions[j] += correct_preds.sum()\n",
    "#         positive_targets[j] += ((gt_races == j) & (targets == 1)).sum()\n",
    "#         positive_preds[j] += np.where(gt_races == j, prediction, 0).sum()\n",
    "#         num_examples[j] += (gt_races == j).sum()\n",
    "\n",
    "#     # if i == 5:\n",
    "#     #     break\n",
    "# zero = 1e-10\n",
    "\n",
    "# total_accuracy = correct_predictions.sum() / total_examples\n",
    "# accuracies = [f\"{a:.2%}\" for a in correct_predictions / (num_examples + zero)]\n",
    "\n",
    "# total_precision = true_pos.sum() / (positive_preds.sum() + zero)\n",
    "# precisions = [f\"{p:.2%}\" for p in true_pos / (positive_preds + zero)]\n",
    "\n",
    "# total_recall = true_pos.sum() / (positive_targets.sum() + zero)\n",
    "# recalls = [f\"{r:.2%}\" for r in true_pos / (positive_targets + zero)]\n",
    "\n",
    "\n",
    "# print(f\"Total accuracy: {total_accuracy:.2%}\\t| \" +\n",
    "#         f\"Accuracies:\\t{accuracies}\\n\")\n",
    "\n",
    "# print(f\"Total precision: {total_precision:.2%}\\t| \" +\n",
    "#         f\"Precisions:\\t{precisions}\\n\")\n",
    "\n",
    "# print(f\"Total recall: {total_recall:.2%}\\t| \" +\n",
    "#         f\"Recalls:\\t{recalls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01/10: 100%|██████████| 28/28 [00:39<00:00,  1.40s/it, loss=0.0946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation epoch 01/10:\n",
      "Total accuracy: 91.29%\t| Accuracies:\t['90.79%', '89.74%', '92.25%', '92.09%', '88.10%', '86.27%', '91.69%']\n",
      "Total precision: 91.64%\t| Precisions:\t['90.18%', '100.00%', '88.64%', '95.97%', '87.50%', '86.57%', '91.76%']\n",
      "Total recall: 88.31%\t| Recalls:\t['97.12%', '76.47%', '86.67%', '90.84%', '91.30%', '82.86%', '87.42%']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02/10: 100%|██████████| 28/28 [00:36<00:00,  1.30s/it, loss=0.0419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation epoch 02/10:\n",
      "Total accuracy: 91.60%\t| Accuracies:\t['90.79%', '92.31%', '92.96%', '92.56%', '90.48%', '85.62%', '91.96%']\n",
      "Total precision: 90.23%\t| Precisions:\t['90.18%', '93.75%', '84.31%', '96.75%', '91.30%', '84.29%', '90.01%']\n",
      "Total recall: 90.79%\t| Recalls:\t['97.12%', '88.24%', '95.56%', '90.84%', '91.30%', '84.29%', '90.26%']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03/10: 100%|██████████| 28/28 [00:36<00:00,  1.30s/it, loss=0.0016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation epoch 03/10:\n",
      "Total accuracy: 92.15%\t| Accuracies:\t['91.45%', '92.31%', '92.25%', '92.56%', '92.86%', '87.58%', '92.52%']\n",
      "Total precision: 91.58%\t| Precisions:\t['90.99%', '93.75%', '85.42%', '96.75%', '91.67%', '88.06%', '91.47%']\n",
      "Total recall: 90.52%\t| Recalls:\t['97.12%', '88.24%', '91.11%', '90.84%', '95.65%', '84.29%', '89.99%']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04/10: 100%|██████████| 28/28 [00:36<00:00,  1.31s/it, loss=0.0010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation epoch 04/10:\n",
      "Total accuracy: 91.95%\t| Accuracies:\t['90.79%', '92.31%', '91.55%', '91.63%', '92.86%', '86.93%', '92.52%']\n",
      "Total precision: 91.99%\t| Precisions:\t['90.91%', '93.75%', '85.11%', '96.69%', '91.67%', '87.88%', '92.17%']\n",
      "Total recall: 89.55%\t| Recalls:\t['96.15%', '88.24%', '88.89%', '89.31%', '95.65%', '82.86%', '89.17%']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05/10: 100%|██████████| 28/28 [00:36<00:00,  1.30s/it, loss=0.0009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation epoch 05/10:\n",
      "Total accuracy: 91.60%\t| Accuracies:\t['90.79%', '89.74%', '90.85%', '91.16%', '90.48%', '86.27%', '92.29%']\n",
      "Total precision: 91.77%\t| Precisions:\t['90.91%', '93.33%', '83.33%', '96.67%', '91.30%', '87.69%', '92.01%']\n",
      "Total recall: 88.93%\t| Recalls:\t['96.15%', '82.35%', '88.89%', '88.55%', '91.30%', '81.43%', '88.77%']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06/10: 100%|██████████| 28/28 [00:36<00:00,  1.30s/it, loss=0.0019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation epoch 06/10:\n",
      "Total accuracy: 91.76%\t| Accuracies:\t['90.79%', '92.31%', '92.25%', '93.02%', '92.86%', '87.58%', '91.96%']\n",
      "Total precision: 90.69%\t| Precisions:\t['90.18%', '93.75%', '84.00%', '96.77%', '91.67%', '88.06%', '90.34%']\n",
      "Total recall: 90.61%\t| Recalls:\t['97.12%', '88.24%', '93.33%', '91.60%', '95.65%', '84.29%', '89.85%']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07/10: 100%|██████████| 28/28 [00:36<00:00,  1.30s/it, loss=0.0008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation epoch 07/10:\n",
      "Total accuracy: 91.64%\t| Accuracies:\t['91.45%', '92.31%', '90.85%', '91.63%', '90.48%', '86.93%', '92.13%']\n",
      "Total precision: 91.25%\t| Precisions:\t['90.99%', '93.75%', '83.33%', '96.69%', '91.30%', '87.88%', '91.16%']\n",
      "Total recall: 89.64%\t| Recalls:\t['97.12%', '88.24%', '88.89%', '89.31%', '91.30%', '82.86%', '89.31%']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08/10: 100%|██████████| 28/28 [00:36<00:00,  1.31s/it, loss=0.0009]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation epoch 08/10:\n",
      "Total accuracy: 91.72%\t| Accuracies:\t['90.79%', '92.31%', '91.55%', '91.16%', '90.48%', '86.93%', '92.29%']\n",
      "Total precision: 91.72%\t| Precisions:\t['90.91%', '93.75%', '85.11%', '96.67%', '91.30%', '87.88%', '91.77%']\n",
      "Total recall: 89.28%\t| Recalls:\t['96.15%', '88.24%', '88.89%', '88.55%', '91.30%', '82.86%', '89.04%']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09/10: 100%|██████████| 28/28 [00:36<00:00,  1.29s/it, loss=0.0027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation epoch 09/10:\n",
      "Total accuracy: 91.56%\t| Accuracies:\t['90.79%', '92.31%', '90.85%', '91.63%', '90.48%', '86.93%', '92.07%']\n",
      "Total precision: 91.09%\t| Precisions:\t['90.18%', '93.75%', '83.33%', '96.69%', '91.30%', '87.88%', '91.03%']\n",
      "Total recall: 89.64%\t| Recalls:\t['97.12%', '88.24%', '88.89%', '89.31%', '91.30%', '82.86%', '89.31%']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 28/28 [00:36<00:00,  1.30s/it, loss=0.0030]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation epoch 10/10:\n",
      "Total accuracy: 91.60%\t| Accuracies:\t['91.45%', '92.31%', '91.55%', '91.16%', '90.48%', '86.93%', '92.07%']\n",
      "Total precision: 92.16%\t| Precisions:\t['91.74%', '93.75%', '86.67%', '96.67%', '91.30%', '87.88%', '92.20%']\n",
      "Total recall: 88.49%\t| Recalls:\t['96.15%', '88.24%', '86.67%', '88.55%', '91.30%', '82.86%', '87.96%']\n",
      "\n",
      "Total Training Time: 0:08:57\n"
     ]
    }
   ],
   "source": [
    "# def compute_accuracy(model, data_loader, device):\n",
    "#     correct_pred, num_examples = 0, 0\n",
    "#     for i, (features, targets) in enumerate(data_loader):\n",
    "#         if i == 5:\n",
    "#             break\n",
    "        \n",
    "#         features = features.to(device)\n",
    "#         targets = targets.to(device)\n",
    "#         probas = sigmoid(fc_layer(model(features))).flatten()\n",
    "#         prediction = probas >= 0.5\n",
    "#         # print(prediction)\n",
    "#         # print((prediction==targets).sum().float().item())\n",
    "        \n",
    "#         num_examples += targets.size(dim=0)\n",
    "#         correct_pred += (prediction == targets).sum().float().item()\n",
    "#     return correct_pred/num_examples * 100\n",
    "\n",
    "def evaluate_metrics(model, data_loader, device, early_stop=-1):\n",
    "    correct_predictions = np.zeros(len(races))\n",
    "    true_pos = np.zeros(len(races))\n",
    "    true_neg = np.zeros(len(races))\n",
    "    positive_preds = np.zeros(len(races))\n",
    "    positive_targets = np.zeros(len(races))\n",
    "    num_examples = np.zeros(len(races))\n",
    "    total_examples = len(data_loader.dataset) \n",
    "\n",
    "    total_it = int(np.ceil(total_examples / data_loader.batch_size))\n",
    "    for i, (features, targets, gt_races) in tqdm(enumerate(data_loader), total=total_it, desc=\"Evaluating\", disable=early_stop > 0):\n",
    "        if i == early_stop:\n",
    "            break\n",
    "\n",
    "        features = features.to(device)\n",
    "        probas = sigmoid(fc_layer(model(features))).flatten()\n",
    "        prediction = (probas >= 0.5).cpu().numpy()\n",
    "        targets = targets.numpy()\n",
    "        gt_races = np.array([races.index(race) for race in gt_races])\n",
    "        \n",
    "        for j in range(len(races)):\n",
    "            correct_preds = (gt_races == j) & (prediction == targets)\n",
    "            true_pos[j] += (correct_preds & (prediction == 1)).sum()\n",
    "            true_neg[j] += (correct_preds & (prediction == 0)).sum()\n",
    "            correct_predictions[j] += correct_preds.sum()\n",
    "            positive_targets[j] += ((gt_races == j) & (targets == 1)).sum()\n",
    "            positive_preds[j] += np.where(gt_races == j, prediction, 0).sum()\n",
    "            num_examples[j] += (gt_races == j).sum()\n",
    "\n",
    "        \n",
    "    zero = 1e-10\n",
    "\n",
    "    total_accuracy = correct_predictions.sum() / num_examples.sum()\n",
    "    accuracies = [f\"{a:.2%}\" for a in correct_predictions / (num_examples + zero)]\n",
    "\n",
    "    total_precision = true_pos.sum() / (positive_preds.sum() + zero)\n",
    "    precisions = [f\"{p:.2%}\" for p in true_pos / (positive_preds + zero)]\n",
    "\n",
    "    total_recall = true_pos.sum() / (positive_targets.sum() + zero)\n",
    "    recalls = [f\"{r:.2%}\" for r in true_pos / (positive_targets + zero)]\n",
    "    return total_accuracy, accuracies, total_precision, precisions, total_recall, recalls\n",
    "\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "    \n",
    "batches_per_epoch = int(np.ceil((size_train * images_per_image_id) / BATCH_SIZE_TRAIN))\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    pbar = tqdm(enumerate(train_loader), total=batches_per_epoch, desc=f\"Epoch {(epoch+1):02d}/{NUM_EPOCHS:02d}\")\n",
    "    for batch_idx, (features, targets, _) in pbar:\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.float().to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        model_output = model(features)\n",
    "        logits = sigmoid(fc_layer(model_output)).flatten()\n",
    "        loss = bin_ce(logits, targets)\n",
    "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        # if batch_idx == 1:\n",
    "        #     break \n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        acc_total, accs, prec_total, precs, rec_total, recs = evaluate_metrics(model, val_loader_total, DEVICE, early_stop=20)\n",
    "        print(f\"Evaluation epoch {(epoch+1):02d}/{NUM_EPOCHS:02d}:\")\n",
    "        print(f\"Total accuracy: {acc_total:.2%}\\t| Accuracies:\\t{accs}\")\n",
    "        print(f\"Total precision: {prec_total:.2%}\\t| Precisions:\\t{precs}\")\n",
    "        print(f\"Total recall: {rec_total:.2%}\\t| Recalls:\\t{recs}\\n\")\n",
    "        # print(  f\"Epoch: {(epoch+1):02d}/{NUM_EPOCHS:02d} | \" + \n",
    "                #f\"Train loss: {loss.item():.4f} |\" +\n",
    "                # f\"Train Acc: {compute_accuracy(model, train_loader, device=DEVICE):.2f}% | \" +\n",
    "                # f\"Val Acc: {compute_accuracy(model, val_loader_total, device=DEVICE):.2f}%\") # | \" + \n",
    "                # f\"Val Acc: {compute_accuracy(model, val_loader_total, device=DEVICE):.2f}%\") # | \" + \n",
    "                #f\"Time elapsed: {get_elapsed_time(start_time)}\\n\")\n",
    "        # for i, race in enumerate(races):\n",
    "        #     print(f\"{race}: {compute_accuracy(model, val_loaders[i], device=DEVICE):.2f}%\", end=\"\\t\")\n",
    "        # print()\n",
    "    \n",
    "print(f\"Total Training Time: {get_elapsed_time(start_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 156/156 [01:29<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation test set:\n",
      "Total accuracy: 91.94%\t| Accuracies:\t['86.52%', '93.67%', '94.64%', '92.00%', '84.24%', '90.88%', '92.53%']\n",
      "Total precision: 89.26%\t| Precisions:\t['85.13%', '92.65%', '89.04%', '91.72%', '80.25%', '84.80%', '90.37%']\n",
      "Total recall: 89.97%\t| Recalls:\t['92.41%', '90.43%', '91.62%', '91.84%', '87.50%', '87.46%', '89.49%']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    acc_total, accs, prec_total, precs, rec_total, recs = evaluate_metrics(model, test_loader_total, DEVICE)\n",
    "    print(f\"Evaluation test set:\")\n",
    "    print(f\"Total accuracy: {acc_total:.2%}\\t| Accuracies:\\t{accs}\")\n",
    "    print(f\"Total precision: {prec_total:.2%}\\t| Precisions:\\t{precs}\")\n",
    "    print(f\"Total recall: {rec_total:.2%}\\t| Recalls:\\t{recs}\\n\")\n",
    "    # print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader_total, device=DEVICE)))\n",
    "\n",
    "    # for i, race in enumerate(races):\n",
    "    #     print(f\"{race}: {compute_accuracy(model, val_loaders[i], device=DEVICE):.2f}%\", end=\"\\t\")\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (features, targets) in enumerate(test_loader_total):\n",
    "\n",
    "#     features = features\n",
    "#     targets = targets\n",
    "#     break\n",
    "    \n",
    "# plt.imshow(np.transpose(features[0], (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# logits, probas = model(features.to(DEVICE)[0, None])\n",
    "# print('Probability Female %.2f%%' % (probas[0][0]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
