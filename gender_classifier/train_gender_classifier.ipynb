{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.system(\"pip install foolbox\")\n",
    "# os.system(\"pip install torchmetrics\")\n",
    "# os.system(\"pip install neptune\")\n",
    "# os.system(\"pip install pandas\")\n",
    "# os.system(\"pip install torchvision\")\n",
    "# os.system(\"CUDA_LAUNCH_BLOCKING=1\")\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18, resnet34, resnet50, densenet121, densenet169, mobilenet_v3_small, mobilenet_v3_large, ResNet18_Weights, ResNet34_Weights, ResNet50_Weights, DenseNet121_Weights, DenseNet169_Weights, MobileNet_V3_Small_Weights, MobileNet_V3_Large_Weights\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import neptune\n",
    "from rtpt import RTPT\n",
    "import foolbox as fb\n",
    "from foolbox import PyTorchModel, accuracy\n",
    "from foolbox.attacks import L2AdditiveGaussianNoiseAttack, LinfFastGradientAttack, LinfDeepFoolAttack\n",
    "from foolbox.criteria import Misclassification\n",
    "import eagerpy as ep\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose experiment\n",
    "size_train = 4992 #86744 #\n",
    "exp_setups = [\"only white\", \"augmented\", \"original\"]\n",
    "is_celeba = False\n",
    "exp = 1\n",
    "\n",
    "# set hyperparameters\n",
    "model_desc = \"resnet34\" #densenet169  resnet34\n",
    "smallest_eps = 0\n",
    "biggest_eps = 2e-3\n",
    "eps_steps = 25\n",
    "eps_attack = [5e-4]#np.linspace(start=smallest_eps, stop=biggest_eps, num=eps_steps)#[] #[2e-4, 1e-4, 5e-5] #[1e-5, 2e-5, 5e-5]# #[5e-5, 1e-4, 5e-4] #[2e-4, 1e-4, 5e-5] #Gaussian: approx. 20, FGSM: approx. 5e-5\n",
    "device = 'cuda:14'\n",
    "lr = 1e-4\n",
    "num_epochs = 100\n",
    "pretrained = True\n",
    "feat_size = (256, 256)\n",
    "bs_train = 128\n",
    "bs_val = 128\n",
    "bs_test = 128\n",
    "scheduler_step_size = 3\n",
    "scheduler_gamma = 0.9\n",
    "\n",
    "# save/load checkpoints\n",
    "ckpt_dir = \"ckpts/\"\n",
    "load_ckpt = False\n",
    "exp_num = 22 + exp # 25 20 21\n",
    "after_epoch = 100\n",
    "# ckpt_load_path = f\"{ckpt_dir}AUGPRE-{exp_num}_{after_epoch}_epochs.pt\"\n",
    "ckpt_load_path = f\"{ckpt_dir}EX-{exp_num}_{after_epoch}_epochs.pt\"\n",
    "save_ckpt_after_epochs = [25, 50, 75, 100] # TODO change\n",
    "\n",
    "\n",
    "# set celeb paths\n",
    "celeb_dir = \"../CelebA/\"\n",
    "celeb_label_dir = celeb_dir + \"labels/\"\n",
    "celeb_img_dir = celeb_dir + \"cropped/\"\n",
    "celeb_img_aug_dir = celeb_dir + \"augmentations/aug_precise_prompts_strong\" #\"CelebA/augmentations/aug_0_5__0/\"\n",
    "celeb_train_csv = f\"train_{size_train}_samples_random.csv\" # \"train_total.csv\"\n",
    "celeb_train_only_white_csv = f\"train_{size_train}_samples_random_white.csv\"\n",
    "celeb_train_aug_csv = \"train_aug_10k_total_fid_harm_precise_prompts.csv\" #\"train_aug_10k_all_samples.csv\"#\"train_aug_10k_distinct_samples_harm.csv\" #f\"train_aug_{size_train}_distinct_samples_correct_gender.csv\"\n",
    "celeb_val_csv = \"val_total.csv\"\n",
    "celeb_test_csv = \"test_total.csv\"\n",
    "\n",
    "\n",
    "# set fairface paths\n",
    "ff_dir = \"../fairface/dataset/\"\n",
    "ff_label_dir = ff_dir + \"labels/\"\n",
    "ff_img_dir = ff_dir + \"fairface-img-margin125-trainval\"\n",
    "ff_img_aug_dir = ff_dir + \"augmentations/mixed_caps_total_84k/\"\n",
    "ff_train_csv = \"permutations/train_1__near_5k.csv\" #\"fairface_label_train.csv\" #\"fairface_label_train_random_10k.csv\" #\n",
    "ff_train_only_white_csv = \"ff_train_only_white_near_5k.csv\"\n",
    "ff_train_aug_csv = \"ff_mixed_caps_near_5k_balanced.csv\"\n",
    "ff_val_csv = \"val.csv\"\n",
    "ff_test_csv = \"test.csv\"\n",
    "\n",
    "\n",
    "races = [\"Black\", \"Indian\", \"Latino\", \"Middle Eastern\", \"Southeast Asian\", \"East Asian\", \"White\"]\n",
    "# ignored_attributes = [\"Black_Hair\", \"Blond_Hair\", \"Brown_Hair\", \"Pale_Skin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define datasets\n",
    "class CelebaDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
    "\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "    \n",
    "        df = pd.read_csv(csv_path, index_col=None)\n",
    "        # print(df.head())\n",
    "        self.img_dir = img_dir\n",
    "        self.csv_path = csv_path\n",
    "        self.img_names = df[\"Image_Name\"].values\n",
    "        self.races = df[\"Race\"].values\n",
    "        # drop_cols = [\"Image_Name\", \"Race\"] + ignored_attributes\n",
    "        # male = df[\"Male\"].replace(\"Male\", 1).replace(\"Female\", 0)\n",
    "        # if \"Original_Gender\" in df.columns:\n",
    "            # df = df.drop(\"Male\", axis=1).rename(columns={\"Original_Gender\": \"Male\"})\n",
    "            # print(df.columns)\n",
    "        self.y = df[\"Male\"].values #df.drop(drop_cols, axis=1).values #\n",
    "        # self.y = np.expand_dims(np.array(df[\"Male\"].values), axis=1) #df.drop(drop_cols, axis=1).values #\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.img_names[index]))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = self.y[index]\n",
    "        gt_race = self.races[index]\n",
    "        return img, label, gt_race\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "    \n",
    "\n",
    "\n",
    "class FairFaceDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading FairFace images\"\"\"\n",
    "\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "    \n",
    "        df = pd.read_csv(csv_path, index_col=None)\n",
    "        # print(df.head())\n",
    "        self.img_dir = img_dir\n",
    "        self.csv_path = csv_path\n",
    "        self.img_names = df[\"Image_Name\"].values\n",
    "        self.races = df[\"Race\"].replace(\"Latino_Hispanic\", \"Latino\").values\n",
    "        self.y = df[\"Gender\"].replace(\"Male\", 1).replace(\"Female\", 0).values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.img_names[index]))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = self.y[index]\n",
    "        gt_race = self.races[index]\n",
    "        return img, label, gt_race\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets based on current experiment\n",
    "num_workers = 6\n",
    "\n",
    "# do normalization here when not performing attack\n",
    "# if do_attack:\n",
    "# custom_transform = transforms.Compose([transforms.Resize(feat_size),\n",
    "#                                     transforms.ToTensor()])\n",
    "# else:\n",
    "custom_transform = transforms.Compose([transforms.Resize(feat_size),\n",
    "                                    transforms.ToTensor()])#,\n",
    "                                    # transforms.RandomHorizontalFlip()]) #,\n",
    "                                    # transforms.Normalize(mean=(0.421, 0.337, 0.301), std=([0.290, 0.269, 0.264]))])\n",
    "                                    # transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\n",
    "\n",
    "# training dataset\n",
    "if is_celeba:\n",
    "\n",
    "    if exp_setups[exp] == \"augmented\":\n",
    "        train_csv = celeb_train_aug_csv\n",
    "        train_img_dir = celeb_img_aug_dir\n",
    "    \n",
    "    else:\n",
    "        if exp_setups[exp] == \"only white\":\n",
    "            train_csv = celeb_train_only_white_csv\n",
    "        else:\n",
    "            train_csv = celeb_train_csv\n",
    "        train_img_dir = celeb_img_dir\n",
    "\n",
    "    train_dataset = CelebaDataset(csv_path=celeb_label_dir + train_csv,\n",
    "                                img_dir=train_img_dir,\n",
    "                                transform=custom_transform)\n",
    "\n",
    "else:\n",
    "    if exp_setups[exp] == \"augmented\":\n",
    "        train_csv = ff_train_aug_csv\n",
    "        train_img_dir = ff_img_aug_dir\n",
    "    \n",
    "    else:\n",
    "        if exp_setups[exp] == \"only white\":\n",
    "            train_csv = ff_train_only_white_csv\n",
    "        else:\n",
    "            train_csv = ff_train_csv\n",
    "        train_img_dir = ff_img_dir\n",
    "    train_dataset = FairFaceDataset(csv_path=ff_label_dir + train_csv,\n",
    "                                    img_dir=train_img_dir,\n",
    "                                    transform=custom_transform)\n",
    "\n",
    "\n",
    "# validation dataset\n",
    "# val_dataset_celeb = CelebaDataset(csv_path=celeb_label_dir + celeb_val_csv,\n",
    "#                             img_dir=celeb_img_dir,\n",
    "#                             transform=custom_transform)\n",
    "\n",
    "val_dataset_ff = FairFaceDataset(csv_path=ff_label_dir + ff_val_csv,\n",
    "                                img_dir=ff_img_dir,\n",
    "                                transform=custom_transform)\n",
    "\n",
    "\n",
    "\n",
    "# test datasets\n",
    "# test_dataset_celeb = CelebaDataset(csv_path=celeb_label_dir + celeb_test_csv,\n",
    "#                             img_dir=celeb_img_dir,\n",
    "#                             transform=custom_transform)\n",
    "\n",
    "test_dataset_ff = FairFaceDataset(csv_path=ff_label_dir + ff_test_csv,\n",
    "                                img_dir=ff_img_dir,\n",
    "                                transform=custom_transform)\n",
    "\n",
    "\n",
    "# create dataloaders on these datasets\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=bs_train,\n",
    "                          shuffle=True,\n",
    "                          num_workers=num_workers)\n",
    "\n",
    "val_loader = DataLoader(dataset=val_dataset_ff,\n",
    "                          batch_size=bs_val,\n",
    "                          shuffle=False,\n",
    "                          num_workers=num_workers)\n",
    "\n",
    "# test_loader_celeb = DataLoader(dataset=test_dataset_celeb,\n",
    "#                           batch_size=bs_test,\n",
    "#                           shuffle=False,\n",
    "#                           num_workers=num_workers)\n",
    "\n",
    "test_loader_ff = DataLoader(dataset=test_dataset_ff,\n",
    "                          batch_size=bs_test,\n",
    "                          shuffle=False,\n",
    "                          num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the mean and standard deviation per channel\n",
    "# channel_means = torch.zeros(3)\n",
    "# channel_stds = torch.zeros(3)\n",
    "# total_samples = 0\n",
    "\n",
    "# for batch in train_loader:\n",
    "#     images, _, _ = batch\n",
    "#     batch_size = images.size(0)\n",
    "#     total_samples += batch_size\n",
    "#     channel_sums = torch.sum(torch.sum(images, dim=2), dim=2)\n",
    "#     channel_means += torch.sum(channel_sums, dim=0)\n",
    "#     channel_stds += torch.sum(torch.sum(torch.sum(images ** 2, dim=2), dim=2), dim=0)\n",
    "\n",
    "# channel_means /= total_samples * images.size(2) * images.size(3)\n",
    "# channel_stds /= total_samples * images.size(2) * images.size(3)\n",
    "# # channel_stds = torch.sqrt(channel_stds - channel_means ** 2)\n",
    "\n",
    "# print(\"Mean per channel:\", channel_means.tolist())\n",
    "# # print(\"Standard Deviation per channel:\", channel_stds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the known means per channel\n",
    "# channel_means = [0,0,0]\n",
    "\n",
    "# # Calculate the standard deviation per channel\n",
    "# channel_stds = torch.zeros(3)\n",
    "# total_samples = 0\n",
    "\n",
    "# for batch in train_loader:\n",
    "#     images, _, _ = batch\n",
    "#     batch_size = images.size(0)\n",
    "#     total_samples += batch_size\n",
    "#     channel_sums = torch.sum(torch.sum(images, dim=2), dim=2)\n",
    "#     channel_stds += torch.sum(torch.sum(torch.sum((images - torch.Tensor(channel_means).reshape(1, 3, 1, 1)) ** 2, dim=2), dim=2), dim=0)\n",
    "\n",
    "# channel_stds /= total_samples * images.size(2) * images.size(3)\n",
    "# channel_stds = torch.sqrt(channel_stds)\n",
    "\n",
    "# print(\"Standard Deviation per channel:\", channel_stds.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick model\n",
    "if model_desc == \"resnet18\":\n",
    "    model = resnet18(weights=(ResNet18_Weights.DEFAULT if pretrained else None))\n",
    "elif model_desc == \"resnet34\":\n",
    "    model = resnet34(weights=(ResNet34_Weights.DEFAULT if pretrained else None))\n",
    "elif model_desc == \"resnet50\":\n",
    "    model = resnet50(weights=(ResNet50_Weights.DEFAULT if pretrained else None))\n",
    "elif model_desc == \"densenet121\":\n",
    "    model = densenet121(weights=(DenseNet121_Weights.DEFAULT if pretrained else None))\n",
    "elif model_desc == \"densenet169\":\n",
    "    model = densenet169(weights=(DenseNet169_Weights.DEFAULT if pretrained else None))\n",
    "elif model_desc == \"mobilenetV3S\":\n",
    "    model = mobilenet_v3_small(weights=(MobileNet_V3_Small_Weights.DEFAULT if pretrained else None))\n",
    "elif model_desc == \"mobilenetV3L\":\n",
    "    model = mobilenet_v3_large(weights=(MobileNet_V3_Large_Weights.DEFAULT if pretrained else None))\n",
    "else:\n",
    "    raise Exception(\"Model not found!\")\n",
    "\n",
    "\n",
    "# adapt model output\n",
    "if model_desc.startswith(\"resnet\"):\n",
    "    model.fc = nn.Sequential(nn.Linear(model.fc.in_features, 256),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Linear(256, 2))\n",
    "    \n",
    "elif model_desc.startswith(\"densenet\"):\n",
    "    model.classifier = nn.Sequential(nn.Linear(model.classifier.in_features, 256),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Linear(256, 2))\n",
    "elif model_desc.startswith(\"mobilenet\"):\n",
    "    model.classifier = nn.Sequential(nn.Linear(model.classifier[0].in_features, 256),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Linear(256, 2))   \n",
    "    \n",
    "else:\n",
    "    raise Exception(\"Model not found!\")\n",
    "\n",
    "model.to(device)\n",
    "# ckpt = torch.load(f\"ckpts/EX-180_25_epochs.pt\", map_location=device)\n",
    "# model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "# ckpt = None\n",
    "# print(f\"Loaded checkpoint: ckpts/EX-180_25_epochs.pt\")\n",
    "\n",
    "\n",
    "# load checkpoint\n",
    "if load_ckpt:\n",
    "    ckpt = torch.load(ckpt_load_path, map_location=device)\n",
    "    model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    ckpt = None\n",
    "    print(f\"Loaded checkpoint: {ckpt_load_path}\")\n",
    "\n",
    "# define loss and create optimizer\n",
    "bin_ce = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"trainable params:\", total_params)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma)\n",
    "\n",
    "do_attack = len(eps_attack) > 0\n",
    "dataset_desc = \"CelebA\" if is_celeba else \"FairFace\"\n",
    "\n",
    "# initialize experiment tracking\n",
    "# run = neptune.init_run(\n",
    "#     project=\"danielritter0508/aug-precise-pre-trained\",\n",
    "#     api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vbmV3LXVpLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9uZXctdWkubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxNDI4OGY4ZC05YmUzLTRjNzAtOTE2NS0xNzU0NTkyMTJiYmUifQ==\",\n",
    "# )\n",
    "run = neptune.init_run(\n",
    "    project=\"MyMasterThesis/experiments\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxNDI4OGY4ZC05YmUzLTRjNzAtOTE2NS0xNzU0NTkyMTJiYmUifQ==\",\n",
    ")\n",
    "\n",
    "run[\"params\"] = {\"dataset\": dataset_desc, \n",
    "                \"experiment\": exp_setups[exp], \n",
    "                \"model_desc\": model_desc,\n",
    "                \"do_attack\": do_attack, \n",
    "                \"eps_min\": smallest_eps,\n",
    "                \"eps_max\": biggest_eps,\n",
    "                \"eps_steps\": eps_steps,\n",
    "                \"learning_rate\": lr, \n",
    "                \"num_epochs\": num_epochs, \n",
    "                \"scheduler_step\": scheduler_step_size, \n",
    "                \"gamma\": scheduler_gamma, \n",
    "                \"pretrained\": pretrained}\n",
    "\n",
    "# init foolbox model if necessary\n",
    "if do_attack:\n",
    "    # batch_iter = iter(train_loader)\n",
    "    # for _ in range(10):\n",
    "    #     batch = next(batch_iter)\n",
    "    #     # ds = da\n",
    "    #     # print(ds)\n",
    "    #     print(torch.mean(batch[0][:,0,:,:]), torch.mean(batch[0][:,1,:,:]), torch.mean(batch[0][:,2,:,:]))\n",
    "    # normalization = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\n",
    "    fool_model = PyTorchModel(model, bounds=(0, 1), device=device)#, preprocessing=normalization\n",
    "    # attack = L2AdditiveGaussianNoiseAttack()\n",
    "    attack = LinfFastGradientAttack()\n",
    "    # attack = LinfDeepFoolAttack()\n",
    "else:\n",
    "    fool_model = None\n",
    "    attack = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize foolbox attack\n",
    "def visualize_attack(images, imgs_mod, epsilons, img_index=0):\n",
    "    \n",
    "    # show original image\n",
    "    print(\"\\noriginal image:\")\n",
    "    image = images[img_index].cpu().numpy()\n",
    "    image = np.moveaxis(image, 0, -1) * 255\n",
    "    image = image.astype(np.uint8)\n",
    "    image = Image.fromarray(image)\n",
    "    image.show()\n",
    "    \n",
    "    # show all noise steps\n",
    "    for i, eps in enumerate(epsilons):\n",
    "        print(f\"noisy image (eps = {eps}):\")\n",
    "        image = imgs_mod[i][img_index].cpu().numpy()\n",
    "        image = np.moveaxis(image, 0, -1) * 255\n",
    "        image = image.astype(np.uint8)\n",
    "        image = Image.fromarray(image)\n",
    "        image.show()\n",
    "\n",
    "\n",
    "# calculate the root of the mean of the squared differences between the values and their average\n",
    "def get_RMSD(values):\n",
    "    # calculate the average of the values\n",
    "    avg = sum(values) / len(values)\n",
    "\n",
    "    # calculate the sum of the squared deviations\n",
    "    squared_deviations_sum = sum(((x - avg) / avg) ** 2 for x in values)\n",
    "    \n",
    "    # calculate the mean squared deviation and take the root of it\n",
    "    rmsd = (squared_deviations_sum / len(values)) ** 0.5\n",
    "    return rmsd\n",
    "\n",
    "\n",
    "# calculate all necessary metrics\n",
    "def evaluate_metrics(model, fool_model, data_loader, device, log_description, show_tqdm=False, decimals=4):\n",
    "    \n",
    "    total_robs = None\n",
    "    robs = None\n",
    "\n",
    "    # initialize all parameters with zeros\n",
    "    correct_predictions, true_pos, true_neg, pos_preds, pos_targets, num_examples = np.zeros((6, len(races)))\n",
    "\n",
    "    # for adversarial attacks\n",
    "    failed_per_race = [torch.tensor([]).reshape((len(eps_attack), 0)) for _ in races]\n",
    "    failed_total = torch.tensor([]).reshape((len(eps_attack), 0))\n",
    "\n",
    "    # iterate through validation/test data and collect necessary basic data\n",
    "    for _, (features, targets, gt_races) in tqdm(enumerate(data_loader), total=len(data_loader), desc=\"Evaluating\", disable=not show_tqdm):#\n",
    "\n",
    "        images = features.to(device)\n",
    "        labels = targets.to(device)\n",
    "        \n",
    "        # prepape annotated races for race-wise split afterwards\n",
    "        gt_races = np.array([races.index(race) for race in gt_races])\n",
    "        \n",
    "        # do adversarial attack and collect results\n",
    "        if fool_model is not None:\n",
    "            # raw, clipped, is_adv\n",
    "            _, _, fail = attack(model=fool_model, inputs=images, criterion=Misclassification(labels), epsilons=eps_attack)\n",
    "            fail = fail.cpu()\n",
    "            \n",
    "            # append results race-wise and total\n",
    "            for i in range(len(races)):\n",
    "                fail_race = fail[:, gt_races==i]\n",
    "                failed_per_race[i] = torch.cat([failed_per_race[i], fail_race], dim=-1)\n",
    "            failed_total = torch.cat([failed_total, fail], dim=-1)\n",
    "            # visualize current attack\n",
    "            # visualize_attack(images, images_mod, eps_attack, img_index=0)\n",
    "            # return\n",
    "  \n",
    "        # do forward pass without gradients\n",
    "        with torch.set_grad_enabled(False):\n",
    "            predictions = torch.argmax(model(features.to(device)), -1).cpu().numpy()\n",
    "\n",
    "        targets = targets.numpy()\n",
    "        \n",
    "\n",
    "        # collect the necessary data split by annotated race\n",
    "        for j in range(len(races)):\n",
    "            correct_preds = (gt_races == j) & (predictions == targets)\n",
    "            true_pos[j] += (correct_preds & (predictions == 1)).sum()\n",
    "            true_neg[j] += (correct_preds & (predictions == 0)).sum()\n",
    "            correct_predictions[j] += correct_preds.sum()\n",
    "            pos_targets[j] += ((gt_races == j) & (targets == 1)).sum()\n",
    "            pos_preds[j] += np.where(gt_races == j, predictions, 0).sum()\n",
    "            num_examples[j] += (gt_races == j).sum()\n",
    "\n",
    "    \n",
    "    # calculate the metrics    \n",
    "    zero = 1e-10\n",
    "\n",
    "    # noise robustness (if attack was done)\n",
    "    if fool_model is not None:\n",
    "        attack_acc_total = 1 - failed_total.float().mean(axis=-1).numpy()\n",
    "        attack_acc_races = np.array([1 - failed_per_race[i].float().mean(axis=-1).numpy() for i in range(len(races))])\n",
    "        # total_robs = (attack_acc_total - 0.5) / (total_acc - 0.5)\n",
    "        # total_robs[total_robs < 0] = 0\n",
    "        # robs = np.array([(attack_acc_races[i] - 0.5) / (accs[i] - 0.5) for i in range(len(races))])\n",
    "        # robs[robs < 0] = 0\n",
    "        predef_total_accs_dn169 = [0.746, 0.752, 0.771]\n",
    "        predef_accs_dn169 = [[0.641, 0.749, 0.799, 0.792, 0.706, 0.737, 0.789], \n",
    "                             [0.666, 0.794, 0.782, 0.805, 0.731, 0.753, 0.743], \n",
    "                             [0.721, 0.811, 0.798, 0.802, 0.757, 0.754, 0.760]] # EX 25 20 21 \n",
    "        \n",
    "        predef_total_accs_rn34 = [0.742, 0.726, 0.750]\n",
    "        predef_accs_rn34 = [[0.601, 0.722, 0.774, 0.813, 0.703, 0.771, 0.800], \n",
    "                            [0.637, 0.747, 0.757, 0.764, 0.703, 0.738, 0.735], \n",
    "                            [0.670, 0.774, 0.776, 0.818, 0.704, 0.752, 0.763]] # AUG-PRE 545 547 548\n",
    "        \n",
    "        predef_total_accs_rn34_pretr = [0.904, 0.909, 0.919]\n",
    "        predef_accs_rn34_pretr = [[0.828, 0.920, 0.929, 0.945, 0.889, 0.883, 0.934], \n",
    "                                  [0.853, 0.936, 0.923, 0.940, 0.909, 0.884, 0.921], \n",
    "                                  [0.894, 0.945, 0.935, 0.945, 0.900, 0.901, 0.918]] # EX 22 23 24\n",
    "        total_robs = attack_acc_total #/ attack_acc_total[0]#total_acc # predef_total_accs_rn34_pretr[exp]#\n",
    "        robs = attack_acc_races #/ np.expand_dims(attack_acc_races[:, 0], axis=1) # accs # predef_accs_rn34_pretr[exp]\n",
    "\n",
    "\n",
    "    # accuracy\n",
    "    total_acc = correct_predictions.sum() / num_examples.sum()\n",
    "    accs = correct_predictions / (num_examples + zero)\n",
    "    # print(total_robs.shape, total_robs)\n",
    "    # print(robs.shape, robs)\n",
    "    # total_acc = total_robs[0]\n",
    "    # accs = robs[:, 0]\n",
    "    \n",
    "    # bias (inter-race accuracy variation)\n",
    "    mad = np.log(max(accs) / min(accs))\n",
    "    rmsd_acc = get_RMSD(accs)\n",
    "\n",
    "    # precision\n",
    "    total_prec = true_pos.sum() / (pos_preds.sum() + zero)\n",
    "    precs = true_pos / (pos_preds + zero)\n",
    "\n",
    "    # recall\n",
    "    total_rec = true_pos.sum() / (pos_targets.sum() + zero)\n",
    "    recs = true_pos / (pos_targets + zero)\n",
    "\n",
    "    # F1 score\n",
    "    total_f1 = 2 * total_prec * total_rec / (total_prec + total_rec)\n",
    "    f1_scores = 2 * precs * recs / (precs + recs)\n",
    "\n",
    "\n",
    "    # round and track race-independent results\n",
    "    total_acc, mad, rmsd_acc, total_prec, total_rec, total_f1 = np.round((total_acc, mad, rmsd_acc, total_prec, total_rec, total_f1), decimals)\n",
    "    metrics = {\"total_acc\": total_acc, \"MAD\": mad, \"RMSD\": rmsd_acc, \"total_prec\": total_prec, \n",
    "               \"total_rec\": total_rec, \"total_f1\": total_f1}\n",
    "    \n",
    "    for (name, value) in metrics.items():\n",
    "        run[log_description + \"/\" + name].append(value)\n",
    "            \n",
    "    if fool_model is not None:\n",
    "        total_robs = np.round(total_robs, decimals)\n",
    "        for eps, rob in zip(eps_attack, total_robs):\n",
    "            run[f\"{log_description}/total_rob/{eps}\"].append(rob) #\n",
    "\n",
    "\n",
    "    # round and track race-specific results\n",
    "    accs, precs, recs, f1_scores = np.round((accs, precs, recs, f1_scores), decimals)\n",
    "    \n",
    "    for race, acc, prec, rec, f1  in zip(races, accs, precs, recs, f1_scores):\n",
    "        run[log_description + \"/acc/\" + race].append(acc)\n",
    "        run[log_description + \"/prec/\" + race].append(prec)\n",
    "        run[log_description + \"/rec/\" + race].append(rec)\n",
    "        run[log_description + \"/f1/\" + race].append(f1)\n",
    "    \n",
    "    if fool_model is not None:\n",
    "        robs = np.round(robs, decimals)\n",
    "        for robs_race, race in zip(robs, races):\n",
    "            for eps, rob in zip(eps_attack, robs_race):\n",
    "                run[f\"{log_description}/rob/{eps}/{race}\"].append(rob) #\n",
    "            \n",
    "            \n",
    "    return total_acc, accs, mad, rmsd_acc, total_f1, f1_scores, total_prec, precs, total_rec, recs, total_robs, robs\n",
    "\n",
    "\n",
    "\n",
    "def get_elapsed_time(start_time):\n",
    "    elapsed = int(time.time() - start_time)\n",
    "    m, s = divmod(elapsed, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return f\"{h}:{m:02d}:{s:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "if not load_ckpt:\n",
    "    start_time = time.time()\n",
    "\n",
    "    rtpt = RTPT('DR', 'Train_Gender_Classifier', num_epochs)\n",
    "    rtpt.start()\n",
    "\n",
    "    print(\"\\nInitiating experiment...\")\n",
    "    print(f\"setup:\\t\\t{exp_setups[exp]}\")\n",
    "    print(f\"model:\\t\\t{model_desc}\")\n",
    "    print(f\"dataset:\\t{dataset_desc}\")\n",
    "    print(f\"lr:\\t\\t{lr}\")\n",
    "    print(f\"trainset size:\\t{size_train}\")\n",
    "    print(f\"pretraining:\\t{pretrained}\")\n",
    "    if do_attack:\n",
    "        print(f\"attacks:\\t{eps_attack}\")\n",
    "    print(f\"device:\\t\\t{device}\\n\")\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {(epoch+1):03d}/{num_epochs:03d}\")\n",
    "        for batch_idx, (features, targets, _) in pbar:\n",
    "            \n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "                \n",
    "            # forward and backward pass\n",
    "            logits = model(features)\n",
    "            targets_exp = F.one_hot(targets).float()\n",
    "            loss = bin_ce(logits, targets_exp)\n",
    "            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "            run[\"train/loss\"].append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # update model params \n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            # if batch_idx == 3:\n",
    "            #     break\n",
    "            # first = features[0].cpu().numpy()\n",
    "            # first = np.moveaxis(first, 0, -1) * 255\n",
    "            # first = first.astype(np.uint8)\n",
    "            # image = Image.fromarray(first)\n",
    "            # print(\"Woman\" if int(targets[0].item()) == 0 else \"Man\")\n",
    "            # image.show()\n",
    "        \n",
    "                # print(\"Gender:\", \"Man\" if targets)\n",
    "\n",
    "        if (epoch+1) in save_ckpt_after_epochs:\n",
    "            ckpt_save_path = ckpt_dir + run[\"sys/id\"].fetch() + \"_\" + str(epoch+1) + \"_epochs.pt\"\n",
    "            \n",
    "            torch.save({\n",
    "                \"model_state_dict\": model.state_dict()\n",
    "            }, ckpt_save_path)\n",
    "            print(f\"Saved checkpoint at: {ckpt_save_path}\")\n",
    "            \n",
    "        model.eval()\n",
    "        # with torch.set_grad_enabled(False): # save memory during inference\n",
    "        evaluate_metrics(model, fool_model, val_loader, device, \"valid\", True)\n",
    "\n",
    "        scheduler.step()\n",
    "        rtpt.step()\n",
    "        \n",
    "    print(f\"Total Training Time: {get_elapsed_time(start_time)}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate experiment on test sets\n",
    "# with torch.set_grad_enabled(False): # save memory during inference\n",
    "print(f\"\\nEvaluation of experiment: '{exp_setups[exp]}'\\n\")\n",
    "\n",
    "# evaluation CelebA\n",
    "# total_acc, accs, MAD, rmsd_acc, total_f1, f1_scores, total_prec, precs, total_rec, recs = evaluate_metrics(model, fool_model, test_loader_celeb, device, \"eval_celeb\", show_tqdm=True)\n",
    "# print(\"\\nEvaluation CelebA test set:\")\n",
    "# print(f\"Total accuracy: {total_acc:.2%}\\t| Accuracies:\\t{accs}\")\n",
    "# print(f\"Maximum accuracy disparity: {MAD}\")\n",
    "# print(f\"Total precision: {total_prec:.2%}\\t| Precisions:\\t{precs}\")\n",
    "# print(f\"Total recall: {total_rec:.2%}\\t| Recalls:\\t{recs}\\n\")\n",
    "\n",
    "# evaluation FairFace\n",
    "model.eval()\n",
    "total_acc, accs, MAD, rmsd_acc, total_f1, f1_scores, total_prec, precs, total_rec, recs, total_robs, robs = evaluate_metrics(model, fool_model, test_loader_ff, device, \"valid\", show_tqdm=True)\n",
    "print(\"\\nEvaluation FairFace test set:\")\n",
    "print(f\"Total accuracy: {total_acc:.2%}\\t| Accuracies:\\t{accs}\")\n",
    "print(f\"Maximum accuracy disparity: {MAD}\")\n",
    "print(f\"Total precision: {total_prec:.2%}\\t| Precisions:\\t{precs}\")\n",
    "print(f\"Total recall: {total_rec:.2%}\\t| Recalls:\\t{recs}\\n\")\n",
    "\n",
    "# print(f\"Total robustnesses:{total_robs}\")\n",
    "# print(f\"Robustnesses:{robs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(robs)\n",
    "# robustness_dir = \"robustness_np_arrays\"\n",
    "# file_path_total = f\"{robustness_dir}/total_rob_{exp_num}_{smallest_eps}_{biggest_eps:.1e}_{eps_steps}_steps.npy\"\n",
    "# file_path_races = f\"{robustness_dir}/robs_{exp_num}_{smallest_eps}_{biggest_eps:.1e}_{eps_steps}_steps.npy\"\n",
    "# np.save(file_path_total, total_robs)\n",
    "# np.save(file_path_races, robs)\n",
    "# # print(np.load(file_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
