{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "# os.system(\"pip install pandas\")\n",
    "# os.system(\"pip install torchvision\")\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import dlib\n",
    "# import argparse\n",
    "# from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect_to_bb(rect):\n",
    "\t# take a bounding predicted by dlib and convert it\n",
    "\t# to the format (x, y, w, h) as we would normally do\n",
    "\t# with OpenCV\n",
    "\tx = rect.left()\n",
    "\ty = rect.top()\n",
    "\tw = rect.right() - x\n",
    "\th = rect.bottom() - y\n",
    "\t# return a tuple of (x, y, w, h)\n",
    "\treturn (x, y, w, h)\n",
    "\n",
    "\n",
    "def detect_faces(input_dir, detections_dir, default_size=300, size=300, padding = 0.25): # default_max_size=800\n",
    "    image_paths = [f\"{input_dir}/{f}\" for f in os.listdir(input_dir)]\n",
    "\n",
    "    cnn_face_detector = dlib.cnn_face_detection_model_v1('dlib_models/mmod_human_face_detector.dat')\n",
    "    sp = dlib.shape_predictor('dlib_models/shape_predictor_5_face_landmarks.dat')\n",
    "\n",
    "    for index, image_path in tqdm(enumerate(image_paths), desc=\"Detecting faces (manually)\"):\n",
    "        # if index < min_index or index > max_index:\n",
    "        #     continue\n",
    "\n",
    "        img = dlib.load_rgb_image(image_path)\n",
    "        \n",
    "        old_height, old_width, _ = img.shape\n",
    "\n",
    "        if old_width > old_height:\n",
    "            new_width, new_height = default_size, int(default_size * old_height / old_width)\n",
    "        else:\n",
    "            new_width, new_height =  int(default_size * old_width / old_height), default_size\n",
    "\n",
    "        # assert old_width >= old_height\n",
    "        # new_width = default_size * int(old_width / old_height)\n",
    "        # new_height = default_size\n",
    "\n",
    "        img = dlib.resize_image(img, rows=new_height, cols=new_width)\n",
    "\n",
    "        dets = cnn_face_detector(img, 1)\n",
    "\n",
    "        num_faces = len(dets)\n",
    "        if num_faces == 0:\n",
    "            print(\"Sorry, there were no faces found in '{}'\".format(image_path))\n",
    "            continue\n",
    "        # Find the 5 face landmarks we need to do the alignment.\n",
    "        \n",
    "        faces = dlib.full_object_detections()\n",
    "        \n",
    "        for detection in dets:\n",
    "            rect = detection.rect\n",
    "            faces.append(sp(img, rect))\n",
    "        images = dlib.get_face_chips(img, faces, size=size, padding = padding)\n",
    "        for idx, image in enumerate(images):\n",
    "            img_name = image_path.split(\"/\")[-1]\n",
    "            # path_sp = img_name.split(\".\")\n",
    "            # face_name = os.path.join(detections_dir,  path_sp[0] + \"_\" + \"face\" + str(idx) + \".\" + path_sp[-1])\n",
    "            face_name = detections_dir + img_name\n",
    "            dlib.save_image(image, face_name)\n",
    "\n",
    "\n",
    "def detect_faces_from_bbox(aug_images_dir, bboxes_path, detections_dir):\n",
    "    \n",
    "    crops = pd.read_csv(bboxes_path)[[\"Left\", \"Top\", \"Right\", \"Bottom\"]].values\n",
    "    default_size = 300\n",
    "\n",
    "    # iterate through all images specified\n",
    "    img_names = [x for x in os.listdir(aug_images_dir)]\n",
    "    for img_name in tqdm(img_names, desc=\"Detecting images (bboxes)\"):\n",
    "        original_img_nmb = int(img_name.split(\"_\")[0])\n",
    "        image = Image.open(aug_images_dir + img_name)\n",
    "        image = image.crop(crops[original_img_nmb - 1])\n",
    "        old_width, old_height = image.size\n",
    "\n",
    "        if old_width > old_height:\n",
    "            new_width, new_height = default_size, int(default_size * old_height / old_width)\n",
    "        else:\n",
    "            new_width, new_height =  int(default_size * old_width / old_height), default_size\n",
    "        image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "        # print(image.size)\n",
    "        # image.show()\n",
    "        image.save(detections_dir + img_name)\n",
    "    #     # break\n",
    "\n",
    "\n",
    "\n",
    "def predict_age_gender_race(save_prediction_at, imgs_path, score_precision=3, append=False, device=\"cuda:0\"):\n",
    "    img_names = [os.path.join(imgs_path, x) for x in os.listdir(imgs_path)]\n",
    "\n",
    "    model_fair_7 = torchvision.models.resnet34(weights=\"DEFAULT\")\n",
    "    model_fair_7.fc = nn.Linear(model_fair_7.fc.in_features, 18)\n",
    "    model_fair_7.load_state_dict(torch.load('fair_face_models/fairface_alldata_7race_20191111.pt', map_location=\"cpu\"))\n",
    "    model_fair_7 = model_fair_7.to(device)\n",
    "    model_fair_7.eval()\n",
    "\n",
    "    # model_fair_4 = torchvision.models.resnet34(weights=\"DEFAULT\")\n",
    "    # model_fair_4.fc = nn.Linear(model_fair_4.fc.in_features, 18)\n",
    "    # model_fair_4.load_state_dict(torch.load('fair_face_models/fairface_alldata_4race_20191111.pt', map_location=\"cpu\"))\n",
    "    # model_fair_4 = model_fair_4.to(device)\n",
    "    # model_fair_4.eval()\n",
    "\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    # img pth of face images\n",
    "    face_names = []\n",
    "    # list within a list. Each sublist contains scores for all races. Take max for predicted race\n",
    "    race_scores_fair = []\n",
    "    gender_scores_fair = []\n",
    "    age_scores_fair = []\n",
    "    race_score_goal = []\n",
    "    race_preds_fair = []\n",
    "    gender_preds_fair = []\n",
    "    age_preds_fair = []\n",
    "    # race_scores_fair_4 = []\n",
    "    # race_preds_fair_4 = []\n",
    "\n",
    "    for img_name in tqdm(img_names, desc=\"Predicting\"):\n",
    "\n",
    "        short_name = img_name.split(\"/\")[1]\n",
    "        wanted_race = int(short_name.split(\"_\")[1])\n",
    "\n",
    "        face_names.append(short_name)\n",
    "        image = dlib.load_rgb_image(img_name)\n",
    "        image = trans(image)\n",
    "        image = image.view(1, 3, 224, 224)  # reshape image to match model dimensions (1 batch size)\n",
    "        image = image.to(device)\n",
    "\n",
    "        # fair\n",
    "        outputs = model_fair_7(image)\n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        outputs = np.squeeze(outputs)\n",
    "\n",
    "        race_outputs = outputs[:7]\n",
    "\n",
    "        # reorder race outputs\n",
    "        reordered_race_outputs = []\n",
    "        reordered_race_outputs.append(race_outputs[1])\n",
    "        reordered_race_outputs.append(race_outputs[5])\n",
    "        reordered_race_outputs.append(race_outputs[2])\n",
    "        reordered_race_outputs.append(race_outputs[6])\n",
    "        reordered_race_outputs.append(race_outputs[4])\n",
    "        reordered_race_outputs.append(race_outputs[3])\n",
    "        reordered_race_outputs.append(race_outputs[0])\n",
    "\n",
    "        race_outputs = reordered_race_outputs\n",
    "        gender_outputs = outputs[7:9]\n",
    "        age_outputs = outputs[9:18]\n",
    "\n",
    "        race_score = np.round(np.exp(race_outputs) / np.sum(np.exp(race_outputs)), score_precision)\n",
    "        race_score_goal.append(race_score[wanted_race])\n",
    "        gender_score = np.round(np.exp(gender_outputs) / np.sum(np.exp(gender_outputs)), score_precision)\n",
    "        age_score = np.round(np.exp(age_outputs) / np.sum(np.exp(age_outputs)), score_precision)\n",
    "\n",
    "        race_pred = np.argmax(race_score)\n",
    "        gender_pred = np.argmax(gender_score)\n",
    "        age_pred = np.argmax(age_score)\n",
    "\n",
    "        race_scores_fair.append(race_score)\n",
    "        gender_scores_fair.append(gender_score)\n",
    "        age_scores_fair.append(age_score)\n",
    "\n",
    "        race_preds_fair.append(race_pred)\n",
    "        gender_preds_fair.append(gender_pred)\n",
    "        age_preds_fair.append(age_pred)\n",
    "\n",
    "        # fair 4 class\n",
    "        # outputs = model_fair_4(image)\n",
    "        # outputs = outputs.cpu().detach().numpy()\n",
    "        # outputs = np.squeeze(outputs)\n",
    "\n",
    "        # race_outputs = outputs[:4]\n",
    "        # race_score = np.round(np.exp(race_outputs) / np.sum(np.exp(race_outputs)), score_precision)\n",
    "        # race_pred = np.argmax(race_score)\n",
    "\n",
    "        # race_scores_fair_4.append(race_score)\n",
    "        # race_preds_fair_4.append(race_pred)\n",
    "\n",
    "    result = pd.DataFrame([face_names,\n",
    "                           race_preds_fair,\n",
    "                        #    race_preds_fair_4,\n",
    "                           gender_preds_fair,\n",
    "                           age_preds_fair,\n",
    "                           race_score_goal,\n",
    "                           race_scores_fair, \n",
    "                        #    race_scores_fair_4,\n",
    "                           gender_scores_fair,\n",
    "                           age_scores_fair, \n",
    "                           ]).T\n",
    "\n",
    "    result.columns = ['Image_Name',\n",
    "                      'Race',\n",
    "                    #   'Race_4',\n",
    "                      'Gender',\n",
    "                      'Age',\n",
    "                      'Race_Score_Goal',\n",
    "                      'Race_Scores',\n",
    "                    #   'Race_Scores_4',\n",
    "                      'Gender_Scores',\n",
    "                      'Age_Scores'\n",
    "                      ]\n",
    "\n",
    "    races = ['Black', 'Indian', 'Latino', 'Middle Eastern', 'Southeast Asian', 'East Asian', 'White']\n",
    "    for i, race in enumerate(races):\n",
    "        result.loc[result['Race'] == i, 'Race'] = race\n",
    "    \n",
    "    # race fair 4\n",
    "    # races_4 = ['White', 'Black', 'Asian', 'Indian']\n",
    "    # for i, race in enumerate(races_4):\n",
    "    #     result.loc[result['Race_4'] == i, 'Race_4'] = race\n",
    "\n",
    "    # gender\n",
    "    result.loc[result['Gender'] == 0, 'Male'] = 1\n",
    "    result.loc[result['Gender'] == 1, 'Male'] = 0\n",
    "\n",
    "    # age\n",
    "    ages = ['0-2', '3-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70+']\n",
    "    for i, age in enumerate(ages):\n",
    "        result.loc[result['Age'] == i, 'Age'] = age\n",
    "\n",
    "    result = result.sort_values(\"Image_Name\")\n",
    "\n",
    "    # pick out which columns you want to save\n",
    "    result = result[['Image_Name',\n",
    "            'Race', \n",
    "            # 'Race_4',\n",
    "            'Gender', \n",
    "            # 'Age',\n",
    "            'Race_Score_Goal',\n",
    "            'Race_Scores',\n",
    "            # 'Race_Scores_4',\n",
    "            'Gender_Scores'\n",
    "            # 'Age_Scores'\n",
    "            ]]\n",
    "    result.to_csv(save_prediction_at, index=False, mode=\"a\" if append else \"w\")\n",
    "\n",
    "    print(f\"Saved results at '{save_prediction_at}'\")\n",
    "\n",
    "\n",
    "def prepare_prediction(input_dir, detections_dir, bboxes_path, use_bboxes, prediction_dir, only_predict):\n",
    "    \n",
    "    # detections should already be prepared\n",
    "    if only_predict:\n",
    "        if not os.path.exists(detections_dir):\n",
    "            raise Exception(f\"There are no detections to predict at '{detections_dir}'!\")\n",
    "        else:\n",
    "            print(f\"Detected faces found at '{detections_dir}'.\")\n",
    "    \n",
    "    # detections have to be created from the inserted image(s) first\n",
    "    else:\n",
    "        if not os.path.exists(input_dir):\n",
    "            raise Exception(f\"There are no images to detect faces at '{input_dir}'!\")\n",
    "\n",
    "        else:\n",
    "            # clear detections directory if necessary\n",
    "            if os.path.exists(detections_dir):\n",
    "                os.system(f\"rm -r {detections_dir}\")\n",
    "            os.makedirs(detections_dir)\n",
    "\n",
    "            # detect faces\n",
    "            if use_bboxes: \n",
    "                detect_faces_from_bbox(input_dir, bboxes_path, detections_dir)\n",
    "            else:\n",
    "                detect_faces(input_dir, detections_dir)\n",
    "            \n",
    "            print(f\"Detected faces saved at '{detections_dir}'.\")\n",
    "\n",
    "    # ensure directory for prediction exists\n",
    "    if not os.path.exists(prediction_dir):\n",
    "        os.makedirs(prediction_dir)\n",
    "    \n",
    "\n",
    "def get_image_number(detections_dir):\n",
    "    detected_faces = [f for f in os.listdir(detections_dir)]\n",
    "    return detected_faces[0].split(\".\")[0].split(\"_\")[0]\n",
    "\n",
    "\n",
    "\n",
    "dlib.DLIB_USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--csv', dest='input_csv', action='store',\n",
    "#                     help='csv file of image path where col name for image path is \"img_path')\n",
    "# args = parser.parse_args()\n",
    "# imgs = pd.read_csv(args.input_csv)['img_path']\n",
    "# imgs = pd.read_csv(input_csv)['img_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting images (bboxes): 100%|██████████| 70000/70000 [07:26<00:00, 156.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected faces saved at 'detected_faces_CelebA_10k_aug_samples_correct_gender/'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 70000/70000 [16:54<00:00, 68.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results at 'outputs/train_aug_10000_distinct_samples_correct_gender.csv'\n"
     ]
    }
   ],
   "source": [
    "# pick device\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device in use: {device}\")\n",
    "\n",
    "# pick directories\n",
    "input_dir = \"../CelebA/aug_0_5__0_gender_spec/\"\n",
    "detections_dir = \"detected_faces_CelebA_10k_aug_samples_correct_gender/\"\n",
    "prediction_dir = \"outputs\"\n",
    "\n",
    "# print(f\"Interval: {(min_index, max_index)}\")\n",
    "\n",
    "# do you want to predict or detect faces first?\n",
    "only_predict = False\n",
    "\n",
    "# do you want to fasten the face detection using bounding boxes?\n",
    "bboxes_path = \"../CelebA/augmentations/bboxes_cropped/448_px_first_10k.csv\"\n",
    "use_bboxes = True\n",
    "\n",
    "# prepare the prediction\n",
    "prepare_prediction(input_dir, detections_dir, bboxes_path, use_bboxes, prediction_dir, only_predict)\n",
    "\n",
    "# create prediction file name\n",
    "# img_name = get_image_number(detections_dir)\n",
    "output_csv = f\"{prediction_dir}/train_aug_10000_distinct_samples_correct_gender.csv\"   # {img_name}_mytest.csv\"\n",
    "\n",
    "# do you want to append the predictions to former predictions?\n",
    "append = False\n",
    "\n",
    "# do the prediction\n",
    "predict_age_gender_race(save_prediction_at=output_csv, imgs_path=detections_dir, append=append, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(\"pip install dlib\")\n",
    "# import dlib.cuda as cuda\n",
    "# print(cuda.get_num_devices())\n",
    "# import dlib\n",
    "# print(cuda.get_num_devices());\n",
    "# print(dlib.cuda.get_num_devices())\n",
    "# print(dlib.cuda.set_device(1))\n",
    "# print(dlib.cuda.get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_for_tables = output_csv\n",
    "# output_gt_table = \"gt_table.csv\"\n",
    "# output_fake_table = \"fake_table.csv\"\n",
    "\n",
    "# predictions = pd.read_csv(input_for_tables)\n",
    "# gt_rows = predictions.loc[predictions[\"face_name_align\"].str.contains(\"_gt_\")]\n",
    "# fake_rows = predictions.loc[~predictions[\"face_name_align\"].str.contains(\"_gt_\")]\n",
    "# append = False\n",
    "\n",
    "# gt_rows[['face_name_align',\n",
    "#             'race', \n",
    "#             # 'race4',\n",
    "#             # 'gender', \n",
    "#             # 'age',\n",
    "#             # 'race_scores_goal',\n",
    "#             'race_scores_fair'\n",
    "#             # 'race_scores_fair_4',\n",
    "#             # 'gender_scores_fair', \n",
    "#             # 'age_scores_fair'\n",
    "#             ]].to_csv(output_gt_table, index=False, mode=\"a\", header=not append)\n",
    "\n",
    "# print(f\"Saved gt results at '{output_gt_table}'\")\n",
    "\n",
    "# fake_rows[['face_name_align',\n",
    "#             'race', \n",
    "#             # 'race4',\n",
    "#             # 'gender', \n",
    "#             # 'age',\n",
    "#             'race_scores_goal',\n",
    "#             'race_scores_fair'\n",
    "#             # 'race_scores_fair_4',\n",
    "#             # 'gender_scores_fair', \n",
    "#             # 'age_scores_fair'\n",
    "#             ]].to_csv(output_fake_table, index=False, mode=\"a\", header=not append)\n",
    "\n",
    "# print(f\"Saved fake results at '{output_fake_table}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_s = pd.read_csv(output_gt_table)\n",
    "# print(\"Mean gt: \", np.mean(gt_s['race_scores_goal']))\n",
    "\n",
    "# fake_s = pd.read_csv(output_fake_table)\n",
    "# print(\"Mean fake: \", np.mean(fake_s['race_scores_goal']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
